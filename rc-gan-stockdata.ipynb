{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch \n",
    "import random\n",
    "\n",
    "import torch.nn as nn \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np \n",
    "\n",
    "from tqdm import tqdm\n",
    "from bokeh.plotting import figure, show\n",
    "from bokeh.io import output_notebook\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "output_notebook()\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CODE FROM TIME-GAN REPO \n",
    "def MinMaxScaler(data):\n",
    "    numerator = data - np.min(data, 0)\n",
    "    denominator = np.max(data, 0) - np.min(data, 0)\n",
    "    return numerator / (denominator + 1e-7)\n",
    "\n",
    "def google_data_loading(seq_length):\n",
    "    # Load Google Data\n",
    "    x = np.loadtxt('GOOGLE.csv', delimiter = \",\",skiprows = 1)\n",
    "    # Flip the data to make chronological data\n",
    "    x = x[::-1]\n",
    "    \n",
    "    # Min-Max Normalizer\n",
    "    x = MinMaxScaler(x)\n",
    "    \n",
    "    dataX = []\n",
    "    for i in range(0, len(x) - seq_length):\n",
    "        _x = x[i:i + seq_length]\n",
    "        dataX.append(_x)\n",
    "    idx = np.random.permutation(len(dataX))\n",
    "    outputX = []\n",
    "    for i in range(len(dataX)):\n",
    "        outputX.append(dataX[idx[i]])\n",
    "    \n",
    "    return outputX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/312443/how-do-you-split-a-list-into-evenly-sized-chunks\n",
    "def chunks(lst, n, leave_last=False):\n",
    "    \"\"\"Yield successive n-sized chunks from lst.\"\"\"\n",
    "    for i in range(0, len(lst), n):\n",
    "        data = lst[i:i + n]\n",
    "        if leave_last and len(data) != n:\n",
    "            break\n",
    "        yield data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def noise_generator():\n",
    "    while True: \n",
    "        data = torch.randn(args['batchsize'], args['seq_len'], args['noise_embed']).to(device)\n",
    "        yield data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stock_generator(batchsize, length, inf_flag):\n",
    "    def gen():\n",
    "        dset = np.array(google_data_loading(length))[:, :, :-1]\n",
    "        idxs = np.arange(dset.shape[0])\n",
    "        random.shuffle(idxs)\n",
    "\n",
    "        for b_idx in chunks(idxs, batchsize, leave_last=True):\n",
    "            bdata = torch.tensor(dset[b_idx]).float().to(device)\n",
    "            yield bdata\n",
    "        \n",
    "    if inf_flag: \n",
    "        while True: \n",
    "            for x in gen(): \n",
    "                yield x \n",
    "    else: \n",
    "        for x in gen(): \n",
    "            yield x "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, emebed, hidden, length):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(emebed, hidden, 3, bidirectional=True)\n",
    "        self.linear = nn.Linear(hidden * 2, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # (bs, seq_len, feat) -> ...\n",
    "        x = x.permute(1, 0, 2)\n",
    "        x, _ = self.lstm(x)\n",
    "        \n",
    "        # permute to (bs, seq, hidden * 2)\n",
    "        features = x.permute(1, 0, 2)\n",
    "        \n",
    "        x = self.linear(features) \n",
    "        return x, features\n",
    "\n",
    "class LSTMRCGenerator(nn.Module):\n",
    "    def __init__(self, embed_size, hidden, out, seq_len):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(embed_size, hidden, 1)\n",
    "        self.linear = nn.Linear(hidden, out)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # (bs, seq_len, feat) -> (seq_len, bs, feat)\n",
    "        x = x.permute(1, 0, 2)\n",
    "        x, _ = self.lstm(x)\n",
    "        \n",
    "        # ... -> (bs, seq, hidden * 2)\n",
    "        features = x.permute(1, 0, 2)\n",
    "        x = torch.tanh(self.linear(features))\n",
    "        return x "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = dict(\n",
    "    experiment_name = 'stock_gan',\n",
    "    # model args \n",
    "    noise_embed = 10, \n",
    "    disc_hidden = 128, \n",
    "    enc_hidden = 128, \n",
    "    seq_len = 30, \n",
    "    gen_feat = 6, \n",
    "    discrim_feat = 6, \n",
    "    \n",
    "    # train args\n",
    "    batchsize = 64,  \n",
    "    max_steps = 50000, \n",
    "    k = 1, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define models \n",
    "generator = LSTMRCGenerator(args['noise_embed'], args['enc_hidden'], args['gen_feat'], args['seq_len']).to(device)\n",
    "discriminator = Discriminator(args['discrim_feat'], args['disc_hidden'], args['seq_len']).to(device)\n",
    "\n",
    "# RCGAN params \n",
    "gen_optim = torch.optim.Adam(generator.parameters())\n",
    "disc_optim = torch.optim.SGD(discriminator.parameters(), 0.1)\n",
    "\n",
    "data_gen = stock_generator(args['batchsize'], args['seq_len'], True)\n",
    "noise_gen = noise_generator()\n",
    "\n",
    "try: \n",
    "    for i in tqdm(range(1, args['max_steps']+1)):\n",
    "        # discrim training\n",
    "        for _ in range(args['k']):\n",
    "            bdata = data_gen.__next__() \n",
    "            noise = noise_gen.__next__()\n",
    "\n",
    "            fake = generator(noise).detach() \n",
    "\n",
    "            fake_dscore, _ = discriminator(fake)\n",
    "            true_dscore, _ = discriminator(bdata)\n",
    "\n",
    "            floss = torch.nn.BCEWithLogitsLoss()(fake_dscore, torch.zeros_like(fake_dscore))\n",
    "            tloss = torch.nn.BCEWithLogitsLoss()(true_dscore, torch.ones_like(true_dscore))\n",
    "            dloss = floss + tloss \n",
    "\n",
    "            # discriminator update\n",
    "            disc_optim.zero_grad()\n",
    "            dloss.backward()\n",
    "            disc_optim.step()\n",
    "\n",
    "        # generator update \n",
    "        noise = noise_gen.__next__()\n",
    "        fake = generator(noise) \n",
    "        fake_dscore, f_features = discriminator(fake)\n",
    "\n",
    "        gloss = torch.nn.BCEWithLogitsLoss()(fake_dscore, torch.ones_like(fake_dscore))\n",
    "\n",
    "        gen_optim.zero_grad()\n",
    "        gloss.backward()\n",
    "        gen_optim.step()\n",
    "        \n",
    "        print('Generator Loss: {:.2f} Discrim Loss: {:.2f}'.format(dloss, gloss))\n",
    "\n",
    "        \n",
    "finally: \n",
    "    torch.save(generator.state_dict(), 'models/stock_gen.mdl')\n",
    "    torch.save(discriminator.state_dict(), 'models/stock_disc.mdl')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(t, obj):\n",
    "    # bokeh plotting\n",
    "    p = figure(title=t, \n",
    "                sizing_mode='stretch_both',\n",
    "                tools=\"xpan,xwheel_zoom,reset,crosshair,save\",\n",
    "                active_drag='xpan',\n",
    "                active_scroll='xwheel_zoom')\n",
    "\n",
    "    bar_width = 1 # 1-day \n",
    "    \n",
    "    h, l, o, c = obj['high'].cpu().numpy(), obj['low'].cpu().numpy(), obj['open'].cpu().numpy(), obj['close'].cpu().numpy()\n",
    "    inc, dec = c > o, c < o\n",
    "    dt = np.arange(len(h))\n",
    "\n",
    "    # plot candles \n",
    "    p.segment(dt, h, dt, l, color=\"black\")\n",
    "    p.vbar(dt[inc], bar_width, o[inc], c[inc], fill_color=\"green\", line_color=\"black\")\n",
    "    p.vbar(dt[dec], bar_width, o[dec], c[dec], fill_color=\"red\", line_color=\"black\")\n",
    "\n",
    "    return p    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sample(data):\n",
    "    obj = {\n",
    "        'open': data[:, 0],\n",
    "        'close': data[:, 1],\n",
    "        'high': data[:, 2],\n",
    "        'low': data[:, 3],\n",
    "    }\n",
    "    p = plot('data', obj)\n",
    "    show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sample(generator, noise_gen):\n",
    "    noise = noise_gen.__next__()[:1]\n",
    "    fake = generator(noise).detach().cpu().squeeze()\n",
    "    return fake "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_sample(generator, noise_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "  <div class=\"bk-root\" id=\"b4ffcc72-eb0c-49ed-889b-b929abbe06e3\" data-root-id=\"1002\"></div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "(function(root) {\n",
       "  function embed_document(root) {\n",
       "    \n",
       "  var docs_json = {\"69f6fd1e-c17d-4b5b-802a-1af5fb5ea14f\":{\"roots\":{\"references\":[{\"attributes\":{\"below\":[{\"id\":\"1013\"}],\"center\":[{\"id\":\"1016\"},{\"id\":\"1020\"}],\"left\":[{\"id\":\"1017\"}],\"renderers\":[{\"id\":\"1035\"},{\"id\":\"1040\"},{\"id\":\"1045\"}],\"sizing_mode\":\"stretch_both\",\"title\":{\"id\":\"1003\"},\"toolbar\":{\"id\":\"1026\"},\"x_range\":{\"id\":\"1005\"},\"x_scale\":{\"id\":\"1009\"},\"y_range\":{\"id\":\"1007\"},\"y_scale\":{\"id\":\"1011\"}},\"id\":\"1002\",\"subtype\":\"Figure\",\"type\":\"Plot\"},{\"attributes\":{\"axis\":{\"id\":\"1017\"},\"dimension\":1,\"ticker\":null},\"id\":\"1020\",\"type\":\"Grid\"},{\"attributes\":{\"source\":{\"id\":\"1042\"}},\"id\":\"1046\",\"type\":\"CDSView\"},{\"attributes\":{},\"id\":\"1056\",\"type\":\"UnionRenderers\"},{\"attributes\":{\"data_source\":{\"id\":\"1042\"},\"glyph\":{\"id\":\"1043\"},\"hover_glyph\":null,\"muted_glyph\":null,\"nonselection_glyph\":{\"id\":\"1044\"},\"selection_glyph\":null,\"view\":{\"id\":\"1046\"}},\"id\":\"1045\",\"type\":\"GlyphRenderer\"},{\"attributes\":{},\"id\":\"1007\",\"type\":\"DataRange1d\"},{\"attributes\":{\"data_source\":{\"id\":\"1032\"},\"glyph\":{\"id\":\"1033\"},\"hover_glyph\":null,\"muted_glyph\":null,\"nonselection_glyph\":{\"id\":\"1034\"},\"selection_glyph\":null,\"view\":{\"id\":\"1036\"}},\"id\":\"1035\",\"type\":\"GlyphRenderer\"},{\"attributes\":{},\"id\":\"1018\",\"type\":\"BasicTicker\"},{\"attributes\":{},\"id\":\"1009\",\"type\":\"LinearScale\"},{\"attributes\":{\"formatter\":{\"id\":\"1048\"},\"ticker\":{\"id\":\"1014\"}},\"id\":\"1013\",\"type\":\"LinearAxis\"},{\"attributes\":{\"line_alpha\":{\"value\":0.1},\"x0\":{\"field\":\"x0\"},\"x1\":{\"field\":\"x1\"},\"y0\":{\"field\":\"y0\"},\"y1\":{\"field\":\"y1\"}},\"id\":\"1034\",\"type\":\"Segment\"},{\"attributes\":{},\"id\":\"1057\",\"type\":\"Selection\"},{\"attributes\":{\"data_source\":{\"id\":\"1037\"},\"glyph\":{\"id\":\"1038\"},\"hover_glyph\":null,\"muted_glyph\":null,\"nonselection_glyph\":{\"id\":\"1039\"},\"selection_glyph\":null,\"view\":{\"id\":\"1041\"}},\"id\":\"1040\",\"type\":\"GlyphRenderer\"},{\"attributes\":{\"bottom\":{\"field\":\"bottom\"},\"fill_alpha\":{\"value\":0.1},\"fill_color\":{\"value\":\"green\"},\"line_alpha\":{\"value\":0.1},\"top\":{\"field\":\"top\"},\"width\":{\"value\":1},\"x\":{\"field\":\"x\"}},\"id\":\"1039\",\"type\":\"VBar\"},{\"attributes\":{},\"id\":\"1014\",\"type\":\"BasicTicker\"},{\"attributes\":{\"x0\":{\"field\":\"x0\"},\"x1\":{\"field\":\"x1\"},\"y0\":{\"field\":\"y0\"},\"y1\":{\"field\":\"y1\"}},\"id\":\"1033\",\"type\":\"Segment\"},{\"attributes\":{\"data\":{\"x0\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29],\"x1\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29],\"y0\":{\"__ndarray__\":\"kj27vBkgYTxovUg8PzogPb0h+TzsB8A7KlWUvGTKhbz/DIk8lgopPYXRKj04j/07KVTLOwPHHT28w+48yWx0PIpMC7uMvI48fVNQPXo9nztpsSq8jf+FvXb2gb1nCaa7lsraPClSXj3jfRE8J1L0PLzkZT1yskc9\",\"dtype\":\"float32\",\"shape\":[30]},\"y1\":{\"__ndarray__\":\"NdJRvSmvgb3sHKy9XTaOvbNbi7x9CAC8IWfzvNniuTxeyxU8ogS8vIKhcLwjzYm7GawhvVYVsLzhs6G8QnxXvPmNDj3CZIe9PoNovYLw3buxLSW9Iwc7vXcaRL0LQRu9eBeQvTLQor0qRmS9RVmivbx7nr0xgCu9\",\"dtype\":\"float32\",\"shape\":[30]}},\"selected\":{\"id\":\"1053\"},\"selection_policy\":{\"id\":\"1052\"}},\"id\":\"1032\",\"type\":\"ColumnDataSource\"},{\"attributes\":{},\"id\":\"1055\",\"type\":\"Selection\"},{\"attributes\":{\"dimensions\":\"width\"},\"id\":\"1021\",\"type\":\"PanTool\"},{\"attributes\":{},\"id\":\"1053\",\"type\":\"Selection\"},{\"attributes\":{\"source\":{\"id\":\"1032\"}},\"id\":\"1036\",\"type\":\"CDSView\"},{\"attributes\":{\"bottom\":{\"field\":\"bottom\"},\"fill_color\":{\"value\":\"green\"},\"top\":{\"field\":\"top\"},\"width\":{\"value\":1},\"x\":{\"field\":\"x\"}},\"id\":\"1038\",\"type\":\"VBar\"},{\"attributes\":{\"text\":\"data\"},\"id\":\"1003\",\"type\":\"Title\"},{\"attributes\":{},\"id\":\"1011\",\"type\":\"LinearScale\"},{\"attributes\":{\"bottom\":{\"field\":\"bottom\"},\"fill_color\":{\"value\":\"red\"},\"top\":{\"field\":\"top\"},\"width\":{\"value\":1},\"x\":{\"field\":\"x\"}},\"id\":\"1043\",\"type\":\"VBar\"},{\"attributes\":{\"formatter\":{\"id\":\"1050\"},\"ticker\":{\"id\":\"1018\"}},\"id\":\"1017\",\"type\":\"LinearAxis\"},{\"attributes\":{\"data\":{\"bottom\":{\"__ndarray__\":\"U156PfNDnjwR/jQ8uX73PPyzqD3Jj9Y8cclBPYT7hD08GXc9Ns+CPYd8ET12mpY8mPcmPZJTmT3shrA9tC2gPWj0qTxK918933+APU9poz1sqa899suUPRJ3UT2o6WU98TNIPTG7ez0NYJM98PtoPevBTj2n8m09\",\"dtype\":\"float32\",\"shape\":[30]},\"top\":{\"__ndarray__\":\"8nZHvRSjuruLzRa9GCY9vTg1fL0DJyy8jHH6usSmB72zr7W8aS4TPGlheLyJwFi9RVBBvV8mbr2Tfbu9L51EvRtWML0+ITe9aqtivXgKrL15+oy9jK9yvQIlkbzseym9n3AKvc7rLL2V3Sm9LTIGvQtEMb26oH69\",\"dtype\":\"float32\",\"shape\":[30]},\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29]},\"selected\":{\"id\":\"1055\"},\"selection_policy\":{\"id\":\"1054\"}},\"id\":\"1037\",\"type\":\"ColumnDataSource\"},{\"attributes\":{\"active_drag\":{\"id\":\"1021\"},\"active_inspect\":\"auto\",\"active_multi\":null,\"active_scroll\":{\"id\":\"1022\"},\"active_tap\":\"auto\",\"tools\":[{\"id\":\"1021\"},{\"id\":\"1022\"},{\"id\":\"1023\"},{\"id\":\"1024\"},{\"id\":\"1025\"}]},\"id\":\"1026\",\"type\":\"Toolbar\"},{\"attributes\":{\"axis\":{\"id\":\"1013\"},\"ticker\":null},\"id\":\"1016\",\"type\":\"Grid\"},{\"attributes\":{\"data\":{\"bottom\":{\"__ndarray__\":\"\",\"dtype\":\"float32\",\"shape\":[0]},\"top\":{\"__ndarray__\":\"\",\"dtype\":\"float32\",\"shape\":[0]},\"x\":[]},\"selected\":{\"id\":\"1057\"},\"selection_policy\":{\"id\":\"1056\"}},\"id\":\"1042\",\"type\":\"ColumnDataSource\"},{\"attributes\":{},\"id\":\"1005\",\"type\":\"DataRange1d\"},{\"attributes\":{},\"id\":\"1054\",\"type\":\"UnionRenderers\"},{\"attributes\":{},\"id\":\"1050\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{},\"id\":\"1048\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{\"dimensions\":\"width\"},\"id\":\"1022\",\"type\":\"WheelZoomTool\"},{\"attributes\":{\"bottom\":{\"field\":\"bottom\"},\"fill_alpha\":{\"value\":0.1},\"fill_color\":{\"value\":\"red\"},\"line_alpha\":{\"value\":0.1},\"top\":{\"field\":\"top\"},\"width\":{\"value\":1},\"x\":{\"field\":\"x\"}},\"id\":\"1044\",\"type\":\"VBar\"},{\"attributes\":{},\"id\":\"1023\",\"type\":\"ResetTool\"},{\"attributes\":{},\"id\":\"1025\",\"type\":\"SaveTool\"},{\"attributes\":{\"source\":{\"id\":\"1037\"}},\"id\":\"1041\",\"type\":\"CDSView\"},{\"attributes\":{},\"id\":\"1024\",\"type\":\"CrosshairTool\"},{\"attributes\":{},\"id\":\"1052\",\"type\":\"UnionRenderers\"}],\"root_ids\":[\"1002\"]},\"title\":\"Bokeh Application\",\"version\":\"2.0.0\"}};\n",
       "  var render_items = [{\"docid\":\"69f6fd1e-c17d-4b5b-802a-1af5fb5ea14f\",\"root_ids\":[\"1002\"],\"roots\":{\"1002\":\"b4ffcc72-eb0c-49ed-889b-b929abbe06e3\"}}];\n",
       "  root.Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
       "\n",
       "  }\n",
       "  if (root.Bokeh !== undefined) {\n",
       "    embed_document(root);\n",
       "  } else {\n",
       "    var attempts = 0;\n",
       "    var timer = setInterval(function(root) {\n",
       "      if (root.Bokeh !== undefined) {\n",
       "        clearInterval(timer);\n",
       "        embed_document(root);\n",
       "      } else {\n",
       "        attempts++;\n",
       "        if (attempts > 100) {\n",
       "          clearInterval(timer);\n",
       "          console.log(\"Bokeh: ERROR: Unable to run BokehJS code because BokehJS library is missing\");\n",
       "        }\n",
       "      }\n",
       "    }, 10, root)\n",
       "  }\n",
       "})(window);"
      ],
      "application/vnd.bokehjs_exec.v0+json": ""
     },
     "metadata": {
      "application/vnd.bokehjs_exec.v0+json": {
       "id": "1002"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_sample(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
